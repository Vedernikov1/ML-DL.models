{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RuBERT_end.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNgkHy/YvfCx7UgJxW/ueU4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vedernikov1/ML-DL.models/blob/main/RuBERT_end.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7hnaiO3HeMar"
      },
      "outputs": [],
      "source": [
        "pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Библиотека с предобученными трансформерами\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "# Для разбиения train выборки\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Библиотеки для классификации\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import xgboost as xgb\n",
        "\n",
        "# Для подсчета метрик\n",
        "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score"
      ],
      "metadata": {
        "id": "1JEzr2NKeVlc"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Константы\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "FILENAME = 'train.tsv'\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "bUDD-gBMgQ25"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Считывание данных"
      ],
      "metadata": {
        "id": "W8LWzVOTyqb8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_dataset(filename):\n",
        "  df = pd.read_csv(\"train.tsv\", sep=\"\\t\")\n",
        "  return df['title'], df['is_fake']"
      ],
      "metadata": {
        "id": "IkL1KjtXhc0l"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = read_dataset(FILENAME)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)"
      ],
      "metadata": {
        "id": "zx7fc9TmgfPR"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Токенизация данных"
      ],
      "metadata": {
        "id": "f5zO5KRey-qY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"sberbank-ai/sbert_large_nlu_ru\")\n",
        "\n",
        "tokenized_train = tokenizer(list(X_train), padding=True, truncation=True, max_length=24, return_tensors='pt')\n",
        "tokenized_train = tokenized_train.to(DEVICE)\n",
        "\n",
        "tokenized_test = tokenizer(list(X_test), padding=True, truncation=True, max_length=24, return_tensors='pt')\n",
        "tokenized_test = tokenized_test.to(DEVICE)"
      ],
      "metadata": {
        "id": "iq_CWurXhL4o"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Получение эмбеддингов предложений"
      ],
      "metadata": {
        "id": "0J3TQSjczTM2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Скачивание предобученной модели\n",
        "model_RuBERT = AutoModel.from_pretrained(\"sberbank-ai/sbert_large_nlu_ru\").to(DEVICE)"
      ],
      "metadata": {
        "id": "lPDxLZ8QiVqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' Данная функция взята с https://huggingface.co '''\n",
        "\n",
        "\n",
        "#Mean Pooling - Take attention mask into account for correct averaging\n",
        "def mean_pooling(model_output, attention_mask):\n",
        "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
        "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
        "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
        "    return sum_embeddings / sum_mask"
      ],
      "metadata": {
        "id": "s7KyoK7hkXd3"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    model_output_train = model_RuBERT(**tokenized_train)\n",
        "with torch.no_grad():\n",
        "    model_output_test = model_RuBERT(**tokenized_test)\n",
        "\n",
        "train_embeddings = mean_pooling(model_output_train, tokenized_train['attention_mask'])\n",
        "test_embeddings = mean_pooling(model_output_test, tokenized_test['attention_mask'])"
      ],
      "metadata": {
        "id": "xjbntgbTjW-j"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Построение моделей классификации"
      ],
      "metadata": {
        "id": "MzyTg-CT0mcR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classification_models = dict()\n",
        "\n",
        "clf = make_pipeline(StandardScaler(), SVC(kernel='rbf', gamma='scale'))\n",
        "clf.fit(train_embeddings.cpu(), y_train)\n",
        "classification_models['SVM'] = clf\n",
        "\n",
        "clf = make_pipeline(StandardScaler(), RandomForestClassifier())\n",
        "clf.fit(train_embeddings.cpu(), y_train)\n",
        "classification_models['RandomForestClassifier'] = clf\n",
        "\n",
        "clf = make_pipeline(StandardScaler(), LogisticRegression())\n",
        "clf.fit(train_embeddings.cpu(), y_train)\n",
        "classification_models['LogisticRegeression'] = clf\n",
        "\n",
        "clf = make_pipeline(StandardScaler(), xgb.XGBClassifier())\n",
        "clf.fit(train_embeddings.cpu(), y_train)\n",
        "classification_models['GBM'] = clf"
      ],
      "metadata": {
        "id": "itNaWZedkM0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Подсчет метрик"
      ],
      "metadata": {
        "id": "dB_Jp2a-01TC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(y_true, y_pred):\n",
        "  metric_scores = dict()\n",
        "\n",
        "  metric_scores['f1_score'] = f1_score(y_true, y_pred)\n",
        "  metric_scores['roc-auc'] = roc_auc_score(y_true, y_pred)\n",
        "  metric_scores['accuracy'] = accuracy_score(y_true, y_pred)\n",
        "\n",
        "  return metric_scores"
      ],
      "metadata": {
        "id": "5AwXttEzn3XB"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model_name, class_model in classification_models.items():\n",
        "  y_pred = np.array(class_model.predict(test_embeddings.cpu()))\n",
        "  metrics = compute_metrics(y_test, y_pred)\n",
        "\n",
        "  print(f'{model_name}:')\n",
        "  for score_name, score in metrics.items():\n",
        "    print(f'{score_name}: {score}')\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0JuY-ZdqoUN",
        "outputId": "a3fde516-3e0b-46f4-80ce-3d4c7288fa74"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM:\n",
            "f1_score: 0.9084687767322498\n",
            "roc-auc: 0.9072953736654805\n",
            "accuracy: 0.9071180555555556\n",
            "\n",
            "RandomForestClassifier:\n",
            "f1_score: 0.860802732707088\n",
            "roc-auc: 0.8586133059895046\n",
            "accuracy: 0.8585069444444444\n",
            "\n",
            "LogisticRegeression:\n",
            "f1_score: 0.874251497005988\n",
            "roc-auc: 0.8725526268170577\n",
            "accuracy: 0.8723958333333334\n",
            "\n",
            "GBM:\n",
            "f1_score: 0.8688245315161841\n",
            "roc-auc: 0.866367090898124\n",
            "accuracy: 0.8663194444444444\n",
            "\n"
          ]
        }
      ]
    }
  ]
}